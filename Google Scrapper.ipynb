{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] User Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0\n",
      "[INFO] Query: \"A great teacher * his\"\n",
      "[INFO] Number of Pages: 3\n",
      "[INFO] Sleeping: 2 Seconds\n",
      "[INFO] URL: https://www.google.com/search?q=%22A%20great%20teacher%20%2A%20his%22&start=0&filter=0 Page # 1\n",
      "[INFO] Sleeping: 9 Seconds\n",
      "[INFO] URL: https://www.google.com/search?q=%22A%20great%20teacher%20%2A%20his%22&start=10&filter=0 Page # 2\n",
      "[INFO] Sleeping: 6 Seconds\n",
      "[INFO] URL: https://www.google.com/search?q=%22A%20great%20teacher%20%2A%20his%22&start=20&filter=0 Page # 3\n",
      "[INFO] 29 Results Saved to CSV File [results_2021_02_27-07_30_43_PM.csv]\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import quote\n",
    "from pprint import pprint\n",
    "import random\n",
    "import csv\n",
    "import re\n",
    "from random import randint\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class GoogleSearchScrapper(object):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        user_agent_list = [\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/13.1.1 Safari/605.1.15',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36',\n",
    "            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10.15; rv:77.0) Gecko/20100101 Firefox/77.0',\n",
    "            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.97 Safari/537.36'\n",
    "        ]\n",
    "        user_agent = user_agent_list[random.randrange(len(user_agent_list))]\n",
    "        self.headers = {\n",
    "            'User-Agent': user_agent,\n",
    "            'Host': 'www.google.com',\n",
    "            'Referer': 'https://www.google.com/'\n",
    "        }\n",
    "        print(\"[INFO] User Agent:\",user_agent)\n",
    "\n",
    "    def __get_source(self, url: str) -> requests.Response:\n",
    "        return requests.get(url, headers=self.headers)\n",
    "\n",
    "    def search(self, query: str, num_of_pages: int) -> list:\n",
    "        results = []\n",
    "        filename = \"results_\"+datetime.now().strftime(\"%Y_%m_%d-%I_%M_%S_%p\")+\".csv\"\n",
    "        with open(filename, 'w', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"query\",\"title\", \"url\", \"description\",\"bold\",\"biased_sentence\"])\n",
    "            for page in range(0,int(num_of_pages)*10,10):\n",
    "                # Sleeping for X seconds\n",
    "                sleep_time = randint(1,10)\n",
    "                print(f\"[INFO] Sleeping: {sleep_time} Seconds\")\n",
    "                sleep(sleep_time)\n",
    "                \n",
    "                # Printing URL and Page Number \n",
    "                url = 'https://www.google.com/search?q=%s' % quote(query)+'&start='+str(page)+'&filter=0'\n",
    "                page_number = int(page/10)\n",
    "                print(f\"[INFO] URL: {url} Page #\",page_number+1)\n",
    "                \n",
    "                response = self.__get_source(url)\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                result_containers = soup.findAll('div', class_='tF2Cxc')\n",
    "\n",
    "                for container in result_containers:\n",
    "                    try:\n",
    "                        title = container.find('h3').text\n",
    "                        url = container.find('a')['href']\n",
    "                        description = container.find('span', class_='aCOpRe').text\n",
    "                        bold = container.find('span', class_='aCOpRe').find('em').text\n",
    "                        bias = re.findall(r\"([^.]*?\"+bold+\"[^.]*\\.)\",description)\n",
    "                    except:\n",
    "                        continue\n",
    "                    writer.writerow([query,title, url, description,bold,bias])\n",
    "                    results.append({\n",
    "                        'query': query,\n",
    "                        'title': title,\n",
    "                        'url': url,\n",
    "                        'description': description,\n",
    "                        'bold': bold,\n",
    "                        'biased_sentence': bias\n",
    "                    })\n",
    "        print(f\"[INFO] {len(results)} Results Saved to CSV File [{filename}]\")\n",
    "        return results\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    GoogleSearchScrapper().search(input('[INFO] Query: '),input('[INFO] Number of Pages: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
